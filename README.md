# ğŸ® Subway Surfers Hand Gesture Controller

Control the popular **Subway Surfers** game using just your **hand gestures**!  
This project uses **Python**, **OpenCV**, and **MediaPipe** to detect real-time hand movements via webcam and map them to keyboard inputs â€” allowing you to play the game touch-free. ğŸ–ï¸â¡ï¸ğŸ’»

---

## ğŸ§  Project Objective

To build a computer vision-based system that detects **hand gestures in real-time** and uses them to control the **Subway Surfers** game using simulated keystrokes (left, right, jump, roll).

---

## ğŸ¥ How It Works

- ğŸ‘ï¸ Webcam captures live video
- ğŸ§  MediaPipe detects hand landmarks (e.g., palm, fingers)
- ğŸ¯ Specific gestures (like swipes or finger positions) are mapped to:
  - **Left/Right Swipe** â†’ Move left/right
  - **Hand Up** â†’ Jump
  - **Hand Down** â†’ Roll
- ğŸ’» PyAutoGUI or `keyboard` library simulates the required keyboard key press

---

## ğŸ› ï¸ Technologies Used

| Tool/Library     | Purpose                                 |
|------------------|------------------------------------------|
| Python           | Main programming language                |
| OpenCV           | Access webcam and process image frames   |
| MediaPipe        | Real-time hand tracking and gesture detection |
| PyAutoGUI/keyboard | Simulate keyboard inputs to game        |
| Numpy            | Image processing and matrix operations   |

---

## ğŸ“ Folder Structure

subway-hand-gesture/
â”‚
â”œâ”€â”€ hand_gesture_controller.py # Main script
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ utils/ # Utility scripts (optional)
â”œâ”€â”€ assets/ # Gesture reference images (optional)
â””â”€â”€ README.md # Project documentation
